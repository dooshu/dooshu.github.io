分形随机性（警告）[55]


我在第十五章的财富数据表中已经演示了分形分布：如果财富从100万翻倍变为200万，至少拥有这一财富的人数就减为1/4，是2的指数倍。如果指数是1，那么至少拥有这一财富的人数会将减为1/2。指数被称为“幂”（所以有“幂律”这一术语）。我们把某事件高于某一水平的发生次数称为“超过数”，200万的超过数是财富超过200万的人数。分形分布的一个特点（另一个特点是突破性）是两个超过数[56] 的比率等于两个相应水平的比率的负幂指数次方。我们来演示这一点。假设你“认为”每年只有96种书能够卖出超过25万册（去年的实际情况就是如此），并且你“认为”指数大约为1.5。你可以推测大约34种书能够卖出超过50万册，只要用96乘以（500 000/250 000）–1.5。我们可以继续计算，大约8种书能够卖出超过100万册，也就是96乘以（1 000 000/250 000）–1.5。





表16–1 不同现象的假设指数


现象 假设指数（近似）

单词的使用频率 1.2

网站点击数量 1.4

美国图书销量 1.5

接到电话的数量 1.22

地震强度 2.8

月球环形山的直径 2.14

太阳耀斑的亮度 0.8

战争强度 0.8

美国人的净资产 1.1

每个姓氏的人数 1

美国城市人口 1.3

市场动荡 3（或更低）

公司规模 1.5

恐怖袭击中的死亡人数 2（但也可能低得多）





资料来源：M·E·J·纽曼


我们来看看不同现象观察到的指数。

我要先说明这些指数没有很高的精确度。一会儿我们就知道为什么，但现在，让我们暂时记住我们并不是观测这些参数，而只是猜测，或者为了统计的目的推测。有时我们很难知道真正的参数，假如它真的存在的话。我们先来看看指数的实际影响。





表16–2 指数的意义


指数 最高的1%观测值对总体的贡献 最高的20%观测值对总体的贡献

1 99.99%* 99.99%

1.1 66% 86%

1.2 47% 76%

1.3 34% 69%

1.4 27% 63%

1.5 22% 58%

2 10% 45%

2.5 6% 38%

3 4.6% 34%





* 显然，对于有限样本不可能出现100%。


表16–2显示了发生概率极低的事件的影响。它列出了样本中最高的1%和20%的观测值对整体的贡献。指数越小，它们的贡献越大。但看看这个过程有多么敏感：在1.1到1.3之间，贡献率能够从66%下降到34%。指数变化0.2能使结果产生巨大的变化，而一个简单的计算错误就能产生这样的差异。这个差异绝不是微不足道：想一想，我们根本不知道精确的指数是什么，因为我们无法直接计算它。我们能做的只是从历史数据中估计它，或者依赖能让我们有点概念的模型理论，但这些模型可能有潜在缺陷，使我们无法盲目地将它们应用于现实。

所以请记住，1.5的指数只是近似，它本身是很难计算的，它不是天上掉下来的，至少来之不易，而且计算时很可能存在巨大的样本误差。你会发现销售超过100万册的图书并不一定是8种，可能是20种，也可能是2种。

更重要的是，指数从某个“临界值”开始起作用，对大于这个临界值的数产生影响。它可能从20万册书开始，也可能从40万册开始。同样，财富在比如6亿美元以上时开始出现不均衡的加剧，而在低于这个数字时呈现不同的特征。你怎么知道临界值在哪里？这是一个问题。我跟我的同事分析了大约2 000万条金融数据。我们都有同样的数据集，但我们从来没能在指数上达成一致。我们知道这些数据符合分形幂律，但明白不可能得出精确的数字。不过知道分布是具有突破性的而且是分形的，这已足够我们做决策。





上限问题


有些人作过研究，并认同分形直到“某个上限”。他们认为，财富、图书销量和市场回报率都存在一个临界点，使得它们不再是分形的。他们提出了“截面”的说法。我同意，可能存在一个分形终止的点，但它在哪里呢？在实践中，说存在一个上限但我不知道它在哪里，与说没有上限是同一回事。提出任何上限都极有可能是错的。你可以说，我们把1 500亿美元作为分析的上限吧。然后另一个人说，为什么不是1 510亿美元？或者，为什么不是1 520亿美元？所以我们把变量当做无上限也是一样。





当心精确的东西


我从经验中总结了一些诀窍：不论我想计算什么指数，最终都可能高估它（请注意较高的指数意味着大离差的影响更小），也就是说，你看到的比你没有看到的较不具有黑天鹅的特征。我称之为化装舞会问题。

假设我生成了一个指数为1.7的随机过程。你看不到生成的机制，只能看到产生的数据。如果我问指数是多少，你很可能算出2.4之类的结果。即使你有100万个数据点，仍可能算错，原因在于有些分形过程要过很久才会显露出特征，于是你低估了这种冲击的严重性。

有时一个分形过程会让你以为它是高斯过程，尤其当采样点很高的时候。在分形分布中，极端离差出现的概率极低，足以迷惑你：你根本没有意识到它是分形分布。





再说一摊水


读者已经看到，不论我们假设世界符合怎样的模型，我们都难以知道模型的参数。所以，对于极端斯坦，归纳问题再次出现，这一次比本书之前提到的更为严重。简而言之，如果某个机制是分形的，它就能够产生很大的值，因此有可能出现大的离差，但可能性有多大，频率有多高，很难准确知道。这与一摊水问题很相似：很多种形状的冰块融化后都可能形成一摊水。作为一个从现实寻找可能的解释模型的人，我与那些做相反事情的人面临截然不同的问题。

我刚刚读了三本“大众科学”书：马克·布坎南的《改变世界的简单法则》、菲利普·鲍尔的《临界点》和保罗·奥默罗德的《为何多数事情归于失败》，它们总结了对复杂系统的研究。这三位作者展现了一个充满幂律的世界，这是一个我相当赞同的视角。他们还指出，许多幂律现象具有普遍性，在各种自然过程和社会群体的行为中有一种奇妙的相似性，这一点我也赞同。他们提出各种关于网络的理论支持他们的研究，并显示了自然科学中的所谓临界现象与社会群体的自我组织之间的联系。他们把产生崩塌事件的过程、社会传染病和信息瀑布效益联系在一起，对此我也赞同。

普遍性正是物理学家对有临界点的幂律问题感兴趣的原因之一。在许多情况下——既包括动态系统理论也包括统计学模型，变量在临界点附近的许多特征独立于相关动态系统。临界点处的指数对于同一群体内的许多系统可能是相同的，即使系统的其他方面各不相同。我几乎同意这种普遍性观点。最后，三位作者都建议我们使用统计物理学的方法，并要像躲瘟疫那样避免使用计量经济学方法和高斯式的非突破性分布，我对此再赞同不过了。

但三位作者要么得出精确的结论，要么鼓吹对精确的追求，因此落入了混淆正向过程与反向过程（问题与反向问题）的陷阱。对我而言，这是最大的科学和认知错误。他们并不是唯一的；几乎每一个与数据打交道但并不基于这些数据做决策的人都会犯同样的错误，这是又一种叙述谬误。在缺乏反馈过程的情况下，你会认为模型证实了现实。我同意这3本书中的观点，但不同意它们的应用方式，当然也不同意作者赋予它们的精确性。实际上，复杂性理论应该让我们对现实的精确模型持更加怀疑的态度。它不会让所有天鹅变白，这是可以预料的：它把它们变灰，而且只变灰。

我在前面已经提到，从认知上讲，世界对于自下而上的经验主义者来说是另一个世界。我们享受不起坐下来研究主宰宇宙的方程的奢侈；我们只是观察数据，对产生数据的真实过程作出假设，根据进一步的信息对方程进行“校准”。随着事件的逐步展开，我们把看到的与曾期望看到的作比较。发现历史是向前发展而不是向后发展的，通常是一个低调的过程，对知道叙述谬误的人来说尤其如此。虽然人们以为商务人士都很自大，但其实这些人在决策与结果、精确模型与现实的差距面前经常感到卑微。

我所说的是现实的迷雾，信息的不完整性，世界推动者的不可见性。历史不会向我们透露它的想法，我们必须猜测。





从表象到现实


上面的观点把本书的各个部分连接在一起。许多人学习心理学、数学或进化论，并试图把它们应用到商务中。我的建议正好相反：研究市场中大量存在的、未知的、强大的不确定性，从而理解对心理学、概率论、数学、决策理论甚至统计物理学都适用的随机性的本质。我们将看到叙述谬误、游戏谬误和伟大的柏拉图化谬误的各种狡猾表现，看到怎样从表象进入现实。

第一次遇见曼德尔布罗特时，我问他，为什么像他这样本来有许多有价值的事可做的、有地位的科学家会对金融这样的庸俗课题感兴趣。我认为从事金融和经济学的人只不过是学到各种各样的经验现实，在他们的银行账户里存上大笔现金，然后就去追求更大更好的东西。曼德尔布罗特的回答是：“数据，数据的金库。”实际上，所有人都忘了他最先从事的是经济学，然后才转入物理学和自然几何学。与如此浩繁的数据打交道令我们感到卑微；它会导致我们犯错误——在表象与现实之间的路上走反了方向。

下面探讨统计循环问题（或称统计回归问题）。假设你需要用历史数据发现某个概率分布是高斯的、分形的或别的什么，你需要确定你是否有足够的数据支持你的论断。我们如何知道数据是否充分呢？根据概率分布来判断，概率分布确实能够告诉你是否有足够的数据对你的推论提出“置信”。如果是高斯钟形曲线，只需要几个数据点就够了（大数定理再次起作用）。而你如何知道相关分布是不是高斯分布呢？好吧，通过数据知道。于是，我们需要数据告诉我们概率分布是什么，又需要概率分布告诉我们需要多少数据。这是一个突出的循环问题。

假如你事前就假定分布是高斯分布，这种循环问题就不会出现。出于某种原因，高斯分布很容易表现出特点。极端斯坦的概率分布不会这样。所以选择高斯分布从而可以借用某种通用法则是一件很方便的事。正是由于这个原因，高斯分布被选为默认分布。我一直反复强调，事前假定高斯分布对少数领域是可行的，比如犯罪统计学、死亡率等平均斯坦问题，但对特性不明的历史数据和极端斯坦问题则行不通。

那么，为什么与历史数据打交道的统计学家不明白这一点呢？首先，他们不喜欢听到他们的整个事业被循环问题取消了。其次，他们没有在严格意义上面对他们的预测结果。我们在马克利达基斯竞争实验中已经看到，他们深陷于叙述谬误中，不愿意听这些。





